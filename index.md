---
layout: homepage
---

## About Me

I am a first-year Ph.D. student at the University of Maryland, 
advised by
<a href="https://www.cs.umd.edu/~sfeizi/">Prof. Feizi</a>
 and
 <a href="https://www.cs.umd.edu/~hajiagha/">Prof. Hajiaghayi</a>.
 
 My research centers around Deep Learning Robustness and Interpretability, with a keen interest in comprehending what models learn, how they utilize their knowledge for predictions, and understanding their successes and failures. I strive to represent these concepts in easily understandable terms, often using languages. I have also contributed to the field of provable defense in Data Poisoning, where our proposed method achieved state-of-the-art results.
 
 In addition to my work in Deep Learning Robustness and Interpretability, I work in the area of Mechanism Design where my focus revolves around delegated choice mechanisms, addressing challenges such as information asymmetry and misaligned utility between principals and agents.

## Research Interests

- **Deep Learning Robustness and Interpretability:** data poisoning, vision-language models, human-understandable explanability.
- **Game Theory:** mechanism design, quality of equilibria.

## News
- **[May. 2023]** We submitted our manuscript "A Regret Analysis of Repeated Delegated Choice" to be reviewed at NeurIPS 2023!
- **[May. 2023]** Our paper "Delegating to Multiple Agents" is accepted to EC 2023!
- **[Apr. 2023]** Our paper "Run-off Election: Improved Provable Defense against Data Poisoning Attacks" is accepted to ICML 2023!
- **[Apr. 2023]** Our paper "Text-To-Concept (and Back) via Cross-Model Alignment" is accepted to ICML 2023!
- **[Feb. 2023]** Our team, UMD RED, is qualified to compete in ICPC NAC 2023 at UCF.

{% include_relative _includes/publications.md %}
{% include_relative _includes/services.md %}
