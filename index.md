---
layout: homepage
---

## About Me

I am a second-year Ph.D. student at the University of Maryland, 
advised by
<a href="https://www.cs.umd.edu/~sfeizi/">Prof. Feizi</a>
 and
 <a href="https://www.cs.umd.edu/~hajiagha/">Prof. Hajiaghayi</a>.
 My research centers around Deep Learning Robustness and Interpretability, with a keen interest in comprehending what models learn, how they utilize their knowledge for predictions, and understanding their successes and failures. I strive to represent these concepts in easily understandable terms, often using languages.
 
 <!-- In addition to my work in Deep Learning Robustness and Interpretability, I work in the area of Mechanism Design where my focus revolves around delegated choice mechanisms, addressing challenges such as information asymmetry and misaligned utility between principal and agents. -->

## Research Interests

- **Deep Learning Robustness and Interpretability:** vision-language models, human-understandable explainability.
- **Game Theory:** mechanism design, quality of equilibria.

## News
- **[May 2024]** Our paper "On Mechanistic Knowledge Localization in Text-to-Image Generative Models" is accepted to ICML 2024.
- **[March 2024]** I will be joining to <a href="">Mosaic</a> at Allen Institute for AI as <strong>Research Intern</strong> in summer 2024!
- **[Jan 2024]** Our papers "PRIME: Prioritizing Interpretability in Failure Mode Extraction" and "Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks" are accepted to ICLR 2024.
- **[Dec 2023]** Our paper "Regret Analysis of Repeated Delegated Choice" is accepted to AAAI 2024.
- **[Nov 2023]** We posted our draft "Online Advertisements with LLMs: Opportunities and Challenges" on arXiv.
- **[Oct. 2023]** Our work "Robustness of AI-Image Detectors: Fundamental Limits and Practical Attacks" was covered by
<a href="https://www.theregister.com/2023/10/02/watermarking_security_checks/">Register</a>, 
<a href="https://www.wired.com/story/artificial-intelligence-watermarking-issues/">Wired</a>, and 
<a href="https://arstechnica.com/ai/2023/10/researchers-show-how-easy-it-is-to-defeat-ai-watermarks/">Arstechnica</a>.
- **[May. 2023]** Our team, UMD RED, ranked 3-rd in ICPC NAC 2023 and proceeded to ICPC World Finals 2023.
- **[May. 2023]** Our paper "Delegating to Multiple Agents" is accepted to EC 2023.
- **[Apr. 2023]** Our paper "Run-off Election: Improved Provable Defense against Data Poisoning Attacks" is accepted to ICML 2023.
- **[Apr. 2023]** Our paper "Text-To-Concept (and Back) via Cross-Model Alignment" is accepted to ICML 2023.
- **[Feb. 2023]** Our team, UMD RED, is qualified to compete in ICPC NAC 2023 at UCF.

{% include_relative _includes/publications.md %}
{% include_relative _includes/services.md %}
